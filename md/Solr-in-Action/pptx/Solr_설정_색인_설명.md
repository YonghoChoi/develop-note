이번 발표에서 다룰 내용은 먼저 solrconfig.xml 파일에 대해서 살펴보고, 새로운 Searcher가 어떻게 생성되는 지, 솔라에서 색인이 어떻게 관리되는지 알아보고, schema.xml 파일에 필드 타입을 정의하는 방법과 document를 추가하는데 사용되는 Update Handler에 대해 알아보도록 하겠습니다.

먼저 솔라가 코어를 발견하는 과정을 살펴보면 SOLR_HOME로 지정된 경로의 하위 디렉토리에서 core.properties 파일을 검색합니다. core.properties 파일을 발견하면 파일에 작성된 정보를 통해 core를 찾아내고 해당 코어의 하위디렉토리에서 solrconfig.xml 파일에 정의된 내용대로 초기화를 수행합니다.

solrconfig.xml 파일에는 이전 시간에 살펴보았던 루씬 버전이나, 확장 라이브러리들이 위치한 경로, 색인 파일이 저장될 위치를 지정할 수가 있고, 이번시간에 알아볼 updateHandler와 캐시에 대한 설정도 정의할 수 있습니다. 

그리고 requestDispacher를 통해 요청을 파싱하는 방법을 정의하고 requestHandler를 통해 쿼리를 어떤 과정을 통해 분석할지 정의할 수가 있습니다. 

그 외의 설정 들은 이번 발표에서는 다루지 않으므로 건너뛰도록 하겠습니다.

솔라는 기본적으로 solrconfig.xml 파일을 항상 감시하고 있지는 않기 때문에 변경사항을 자동으로 감지할 수는 없습니다. 그래서 솔라 콘솔 에서는 Reload 버튼을 통해 변경된 파일을 적용하도록 기능을 제공하고 있습니다.

클라이언트가 요청한 쿼리를 처리하는 방법을 살펴보면, 먼저 HTTP GET 요청으로 쿼리를 수행합니다. 그리고 난 후 서버에서는 Jetty를 통해 요청을 받아들이고, 요청 경로에 포함된 /solr 컨텍스트를 사용해서 requestDispacher로 라우팅 됩니다. 여기서 requestDispacher는 /* 에 매핑되는 서블릿 필터를 의미합니다.  /solr 뒤에 오는 부분을 코어명으로 인식해서 해당 코어의 solrconfig.xml 파일을 통해 요청을 처리하게 됩니다. 여기서는 collection1이라는 코어의 select request handler를 사용하여 요청을 처리하게 됩니다. 뒤에서 알아보겠지만 select request handler에 정의된 파이프라인을 통해 요청을 처리합니다. 이렇게 처리된 결과는 response writer 컴포넌트로 처리되어서 클라이언트에게 반환됩니다.

앞서 클라이언트의 요청을 처리하는 request handler에 대해 알아보도록 하겠습니다. 예제에서 사용된 request handler는 앞서 봤던 solrconfig.xml 파일에 select라는 이름으로 정의가 되어 있고 solr.SearchHandler 클래스를 사용합니다. SearchHandler 클래스는 그림과 같은 과정을 통해 요청을 처리합니다.  먼저 요청 파라미터를 적용하는데 이 parameter로 전달된 값에 따라 defaults를 사용할지 아니면 appends, invariants를 사용할지 결정하게 됩니다. 그 다음으로 first components에 등록된 conponent들을 처리하게 되는데 이는 선택 사항이므로 존재하지 않을 수도 있습니다. 다음으로 주 컴포넌트들이 체이닝 방식으로 수행이 되는데 쿼리 같은 경우에는 필수적으로 존재해야 하는 컴포넌트입니다. 그림에서처럼 쿼리를 수행한 뒤 패싯을 처리하고 순차적으로 처리가 됩니다. 다음으로는 last-components로 등록된 컴포넌트들이 수행되고 이 또한 first-components와 마찬가지로 선택사항입니다. 이제 각 컴포넌트들에 대해 하나씩 살펴보도록 하겠습니다.

먼저 요청 파라미터들을 적용하는 방법에 대해 알아보도록 하겠습니다. defaults는 요청에 명시적으로 지정하지 파라미터들을 기본 값으로 사용하도록 하고, invariants는 요청 시 인자가 지정되어 있더라도 solrconfig.xml에 설정된 값을 사용하도록 합니다. 이는 클라이언트가 요청에 사용하면 안되는 파라미터에 대해 사용하지 못하도록 잠그는 용도로 사용 합니다. 마지막으로 appends는 클라이언트가 제공한 매개변수에 더해서 추가적으로 값을 사용합니다. 

다음으로 요청 처리의 주 컴포넌트들에 대해 알아보겠습니다. 그림에 나와있는 6가지의 검색 컴포넌트들은 기본적으로 솔라에 내장되어 있습니다.  먼저 쿼리 컴포넌트는 쿼리를 처리하는 이 파이프라인에서 핵심이 되는 컴포넌트입니다. 이 컴포넌트는 쿼리와 일치하는 모든 document를 찾아냅니다. 찾아낸 결과는 파이프라인을 통해 패싯으로 전달됩니다.  패싯 컴포넌트를 통해 필드 단위로 패싯을 계산하게 되는데 이에 대해서는 8장에서 자세히 다루고 있습니다. 그 뒤에 컴포넌트들도 체이닝 방식으로 수행이 되고 각 항목들은 이전에 살펴본 내용이므로 넘어가도록 하겠습니다.

first 또는 last 컴포넌트들은 주 검색 컴포넌트들을 처리하기 전이나 후에 수행할 컴포넌트들을 array 방식으로 제공하고 있어서 위와 같이 last-component에 spellcheck를 지정하게 되면 검색 컴포넌트들을 수행하고 난 뒤에 맞춤법 검사를 수행하게 됩니다.

다음으로 새로운 Searcher가 생성되는 과정에 대해 살펴보도록 하겠습니다. 솔라의 색인에 새 문서가 추가되면 현재의 searcher에 바로 반영이 되지 않습니다.  클라이언트에게 새롭게 갱신된 문서를 반환하도록 하려면 현재 열려있는 searcher를 닫고 업데이트 된 searcher를 새로 생성해야 합니다. 하지만 기존 searcher를 닫고 새로운 searcher를 생성하기까지는 일정 시간이 필요하기 때문에 이 과정 중에는 클라이언트의 요청 처리를 제대로 수행할 수가 없습니다. 그래서 솔라는 새로운 Searcher의 준비작업을 백그라운드에서 수행하고, 준비 될때까지 기존의 searcher를 사용합니다. 또한 새로운 searcher가 준비되더라도 실행 중인 쿼리가 있는 경우에는 쿼리가 완료될때까지 대기를 했다가 교체를 합니다.

이처럼 솔라는 쿼리 성능이 느려지는 것보다는 차라리 문서 갱신 시간이 다소 느리더라도 빠른 시간내에 결과를 반환하는 것을 우선으로 하고 있습니다. 이러한 warming 과정 중에 warming을 수행할 쿼리 목록이 많을 수록 새로운 Searcher를 준비하는데 많은 시간이 소요되기 때문에 warming 쿼리 목록을 적게 유지하는 것이 좋습니다. warming 방법으로는 cache-warming과 autowarming이 존재합니다.

먼저 cache-warming은 그림과 같이 warming을 수행할 쿼리를 미리 등록해놓는 것입니다. 그래서 new Searcher 이벤트가 발생할 때마다 그림에 설정된 쿼리가 수행되고 결과가 캐싱됩니다. 이 과정은 쿼리를 수행하는 비용이 들기 때문에 솔라에서는 설정에 주석처리가 된 것처럼 이를 수행할지 말지에 대한 여부는 개발자의 몫으로 남겨두었습니다.

조금 전 설명에서 색인에 변경이 발생할 경우 새로운 searcher를 백그라운드에서 준비를 시킨다고 했었는데 이 준비과정 중에 색인에 또다른 커밋이 발생할 수 있습니다. 이는 이 변경에 대해 또 다른 searcher를 준비시켜야 한다는 것을 의미하기 때문에 Searcher가 너무 많아질 수 있습니다. 이렇게 준비 중인 Searcher가 많아질수록 성능은 점점 떨어지기 때문에 솔라에서는 동시에 warming을 수행할 수 있는 max치를 설정할 수 있게 하였습니다.

다음으로 autowarming은 현재 사용 중인 searcher의 캐시 일부를 새로운 searcher에 업데이트를 합니다.  이를 통해 warming 시간을 단축할 수 있지만 갱신된 내용을 100% 사용하지 못할 수도 있습니다. 솔라에서는 기존 searcher의 캐시에 대한 비율을 백분율로 설정할 수 있는 autowarmCount를 제공합니다.

솔라는 캐싱된 모든 객체를 메모리에 유지하기 때문에 캐시가 너무 커질 경우 JVM 메모리를 모두 차지할 수도 있습니다. 그렇기 때문에 LRU나 LFU 방식으로 관리가 필요합니다. LRU는 캐시에서 마지막으로 요청된 시간을 기반으로 캐시가 max치에 도달할 경우 객체를 제거하고, LFU는 캐시에 요청되는 빈도에 따라 객체를 제거합니다. 또한 기본 캐시 크기를 너무 크게 잡게되면 JVM에서 가비지 컬렉션 시간이 길어지기 때문에 성능에 영향을 줄 수 있습니다.

이제 색인을 생성하는 과정에 대해 알아보도록 하겠습니다. 텍스트로 된 문서를 색인화 하기 위해서는 XML 또는 JSON과 같은 솔라가 지원하는 형식으로 변환해야 합니다.  클라이언트에서 새로운 document를 추가하는데는 일반적으로 HTTP POST와 같은 인터페이스를 사용합니다. 앞서 살펴 본 new searcher와 같이 변경된 색인을 적용합니다.

색인에 document를 추가하려면 클라이언트에서 그림과 같이 솔라에서 지원하는 XML이나 JSON 형식으로 document의 내용을 전달합니다.

솔라 코어에서는 추가될 문서 정보를 받아 Update Handler를 통해 처리되고 이는 분석과정을 거쳐서 루씬 색인 파일에 적용됩니다.  이 때 각 필드에 대한 타입 정보는 schema.xml을 참조합니다. 

schema.xml 파일의 요소들은 이전에 살펴봤으므로 넘어가고, 여기서 특정 필드들에 대해 추가적으로 알아보도록 하겠습니다. 

먼저 다중 값 필드는 하나의 필드가 여러개의 값을 가져야할 경우에 사용됩니다. 예를 들어 하나의 document에서 참조해야할 link가 여러개 있다면 필드 하나만으로는 원하는 결과를 얻지 못할 것입니다. 이 때 다중값 필드를 사용하면 해당 필드의 이름을 가진 모든 필드에서 일치하는 값을 검색하도록 할 수 있습니다. schema.xml 파일에는 field 정의 부분에 multiValuued 값을 true로 설정하면 그림에서와 같이 같은 이름을 가진 여러개의 필드를 사용할 수 있습니다.

다음으로 복사 필드는 사본을 만들어서 여러 개의 필드 타입을 적용할 수 있도록 합니다. 대부분의 검색 프로그램에서는 쿼리를 입력할 단일 검색 상자가 제공되는데 해당 검색 상자가 검색할 필드가 text라고 가정하면 link 주소를 입력할 경우 원하는 결과를 얻지 못할 것입니다. 이때 복사 필드를 사용하면 사본에 여러 필드의 내용이 복사되어 더해지므로 하나의 필드를 통해 여러 타입의 값을 검색할 수 있게됩니다. 일반적으로 클라이언트가 쿼리할 필드를 지정하지 않은 경우 기본 쿼리 필드로 사용하기 위해 사용됩니다. 하지만 이는 색인 파일의 크기를 증가시키기 때문에 디스크 공간을 고려해야 합니다.

솔라에서는 색인 생성 중에 중복을 피하기 위해서 고유키 필드를 사용합니다. 고유키가 존재하지 않는다면 동일한 내용의 문서가 존재하더라도 계속해서 색인데 document가 추가될 것입니다. 고유키를 지정하게 되면 동일한 키를 갖는 document는 해당 document를 덮어쓰게됩니다. 여러 서버에 솔라 색인을 배포하려는 경우 고유키 필드를 제공해야 하므로, 애초에 고유키 필드를 정의해두는 것이 좋습니다.

색인에 새로운 document를 추가하기 위해 솔라에 document를 전달하는 방법에 대해 알아보도록 하겠습니다. 앞서 설명했던 것과 같이 XML이나 JSON 문서를 사용해서 document를 추가할 수 있습니다. 다이나믹 필드를 사용하면 schema.xml 파일을 변경하지 않아도 되므로 편의상 많이 많이 사용합니다.

다음으로 자바 기반의 라이브러리인 SolrJ는 솔라에 연결해서 document를 추가하거나 쿼리를 실행할 수 있도록 해줍니다. 내부적으로는 Apache HttpComponents 라이브러리를 사용하여 솔라와 통신을 하고,  기본적으로 javabin이라는 내부 바이너리 프로토콜을 사용하고 있는데 이는 XML이나 JSON 보다 효율적인 통신 방법입니다. 그 외에도 대규모 인덱싱, Solr 인스턴스 간 로드밸런싱, SolrCloud에서 Solr 서버의 위치 자동발견 기능 등 다양하게 사용할 수 있습니다. 

SolrJ 외에 document를 솔라로 전달하기 위한 툴로는 Data Import Handler와 ExtractingRequestHandler, Nutch가 있습니다. Data Import Handler는 관계형 데이터베이스에서 데이터를 가져오는 기능을 제공합니다. 그리고 ExtractingRequestHandler는 Tika를 사용하여 PDF나 MS Office와 같은 이진 파일을 솔라에 전달하고 솔라가 텍스트를 추출하여 색인을 생성 합니다. 마지막으로 Nutch는 Java 기반 오픈소스 웹 크롤러로 웹페이지를 수집하여 솔라로 전달하여 색인을 생성합니다.

이제 마지막으로 새로운 document 추가 요청을 처리하는 Update Handler에 대해 알아보도록 하겠습니다. 클라이언트로부터 새로운 document를 추가해달라는 요청이 들어오면 솔라에서는 Update Handler를 통해 이를 처리합니다. 앞서 설명한바와 같이 XML, JSON, CSV, javabin등의 형식을 지원합니다.  solrconfig.xml파일의 updateHandler 설정을 보면 로그가 어느 경로에 저장될지, Commit과 이벤트 리스너는 어떠한 방법으로 수행할지에 대한 설정을 정의 할 수가 있습니다.  

Normal 커밋은 하드 커밋이라고도 하는데 커밋되지 않은 모든 문서를 디스크에 플러시하고 searcher 내부 구성 요소를 새로 고친 후에 커밋된 문서를 검색할 수 있도록 합니다. 새로운 searcher를 생성하기 때문에 쿼리 성능에 영향을 줄 수 있습니다. 커밋이 성공하면 새로 커밋된 문서는 영구 저장 장치에 안전하게 보존이 되지만 디스크 장애가 발생할 수 있으므로 이에 대한 조치를 수행할 수 있는 솔루션이 필요합니다.

Soft 커밋은 디스크로 플러시하는 절차가 없기 때문에 하드 커밋에 비해서 비용이 낮습니다. 그러므로 수시로 커밋이 가능하고 실시간에 근접한 검색을 지원합니다. 하지만 이 또한 일정 시점에서는 디스크와 같은 내구성 있는 저장소로 플러시 되는 것을 보장하기 위해서 하드커밋을 수행해야 합니다.

Auto 커밋은 세가지 타입으로 분류해볼 수가 있는데 지정된 시간 내에 각 문서들을 커밋하거나, 커밋되지 않은 문서의 수가 인계치에 도달하면 모든 문서를 커밋하거나 10분 간격과 같이 주기적으로 커밋을 수행합니다. 예시에 나와있는 것처럼 시간 주기, 커밋되지 않은 문서 수에 따른 자동 커밋기능을 설정할 수 있습니다. 자동 커밋을 수행하면 새로운 searcher가 생성되는데 openSearcher 값을 false로 해서 비활성화 할 수 있습니다. 하지만 이 경우 문서를 검색하기 위해서는 소프트 커밋이 필요합니다. 

솔라에서 수락한 업데이트 요청은 색인에 커밋 될 때까지 영구 저장소에 저장됩니다. 이 때 업데이트 요청 처리 도중 문제가 발생할 경우 Transaction Log가 없다면 문서가 손실됩니다. 

업데이트 핸들러가 처리되는 전반적인 과정을 살펴보면 먼저 클라이언트가 솔라 서버로 HTTP POST를 사용하여 업데이트 요청을 합니다. 그러면 Jetty의 servlet을 통해 요청이 라우팅 됩니다. 요청 받은 솔라의 코어에서는 URL에 명시된 이름으로 solrconfig.xml 파일에 등록 된 request handler를 검색합니다. 여기서는 update 입니다. update request handler는 문서를 추가하거나 갱신하기 위해 schema.xml 파일을 사용하고, 앞서 봤던 체이닝 방식으로 요청을 처리 합니다. ADD 요청이 트랜잭션 로그에 기록이 되고 업데이트 요청은 디스크의 루씬 색인파일로 안전하게 저장됩니다. 정상적으로 처리가 완료되면 response writer를 사용해서 클라이언트 응용 프로그램에 응답을 전송합니다. 

데이터베이스는 row 단위로 update를 수행할 수 있는 반면에 솔라는 필드를 업데이트 하기 위해서는 document 전체를 갱신해야 합니다. 아토믹 업데이트는 내부적으로는 업데이트를 위해 document를 제거하고 생성하는 것은 같지만 클라이언트는 필드만 업데이트 되는 것처럼 느껴지도록 이러한 과정을 감춥니다. 